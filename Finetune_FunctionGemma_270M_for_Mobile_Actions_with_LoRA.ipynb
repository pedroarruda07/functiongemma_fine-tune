{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "926bada6"
      },
      "source": [
        "Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a110dfce"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkOtOq0jDE0c"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "      <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/gemma-cookbook/blob/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e624ec07"
      },
      "source": [
        "# Fine-tune FunctionGemma 270M for Mobile Actions\n",
        "\n",
        "This notebook fine-tunes FunctionGemma for the task of taking user request to perform mobile actions through the Hugging Face Transformer Reinforcement Learning ([TRL](https://huggingface.co/docs/trl/en/index)) library.\n",
        "\n",
        "When training [FunctionGemma 270M](https://huggingface.co/google/functiongemma-270m-it) on a Google Colab A100 GPU accelerator, this process can take 60 minutes end-to-end. Run each code snippet to:\n",
        "\n",
        "1. Set up the Colab environment\n",
        "2. Prepare a dataset for fine-tuning\n",
        "3. Load and test the base FunctionGemma 270M model\n",
        "4. Fine-tune the model\n",
        "5. Test, evaluate, and save the model for further use\n",
        "6. Convert the checkpoint to `.litertlm` for deployment\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "This colab needs the **A100 GPU**. You will need a Colab Pro subscription or Colab Pay to Go with credits.\n",
        "\n",
        "## Set up development environment\n",
        "\n",
        "The first step is to install the necessary libraries using the `pip` package installer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BEK9IfKBqQaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40491adb-a0cd-428a-e61b-3e7ffe042bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: transformers==4.57.1 in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: trl==0.25.1 in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: datasets==4.4.1 in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.25.1) (1.12.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl==0.25.1) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl==0.25.1) (2.9.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets==4.4.1) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets==4.4.1) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==4.4.1) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl==0.25.1) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "%pip install torch\n",
        "%pip install -U transformers==4.57.1 trl==0.25.1 datasets==4.4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTuW1LPfLXi9"
      },
      "source": [
        "**You may have to restart your session (runtime) to use newly installed libraries.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ef3d54b"
      },
      "source": [
        "##Enable Hugging Face permissions\n",
        "\n",
        "To use Gemma models, you'll need to accept the model usage license and create an Access Token:\n",
        "\n",
        "1. **Accept license** on the [model page](http://huggingface.co/google/functiongemma-270m-it).\n",
        "\n",
        "2. **Get a valid [Access Token](https://huggingface.co/settings/tokens) with 'Write' access (very important!)**\n",
        "\n",
        "3. **Create a new Colab secret** in the left toolbar. Specify `HF_TOKEN` as the 'Name', add your unique token as the 'Value', and toggle 'Notebook access' on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b6d79c93"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Login into Hugging Face Hub\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0eb2e06"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "You can access [FunctionGemma 270M](https://huggingface.co/google/functiongemma-270m-it) from Hugging Face Hub by accepting the license terms. The instruction-tuned version of the model has already been trained on how to follow directions and with fine-tuning, you'll now adapt it to a new task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "18069ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4c1e7d-c1d4-4bc8-bb4f-868393fd36c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "DType:  torch.bfloat16\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "gemma_model = \"google/functiongemma-270m-it\"\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    gemma_model,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"eager\",\n",
        "    dtype=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(gemma_model)\n",
        "\n",
        "print(f\"Device: {base_model.device}\")\n",
        "print(f\"DType:  {base_model.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hI4twbrz0xj"
      },
      "source": [
        "Device should print as `cuda` if you're using a GPU runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB0Fo8MRbxxY"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "To fine-tune FunctionGemma, we utilize the [Mobile Actions\n",
        "dataset](https://huggingface.co/datasets/google/mobile-actions), which is\n",
        "publicly available on Hugging Face. Each entry in this dataset provides:\n",
        "\n",
        "*   The set of tools (functions) the model can use:\n",
        "    1. Turn the flashlight on\n",
        "    2. Turn the flashlight off\n",
        "    3. Create a contact in the phone's contact list\n",
        "    4. Send an email\n",
        "    5. Show a location on the map\n",
        "    6. Open the WiFi settings\n",
        "    7. Create a new calendar event\n",
        "*   The system prompt providing the context like current date and time\n",
        "*   The user prompt, like `turn on the flashlight`.\n",
        "*   The expected model response, including the appropriate function calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N2AwsZMkRioU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285f6661-1937-46d4-ba2c-7d6e87f00f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mHere's an example from your dataset:\u001b[0m \n",
            "{\n",
            "  \"metadata\": \"train\",\n",
            "  \"tools\": [\n",
            "    {\n",
            "      \"function\": {\n",
            "        \"name\": \"turn_on_flashlight\",\n",
            "        \"description\": \"Turns the flashlight on.\",\n",
            "        \"parameters\": {\n",
            "          \"type\": \"OBJECT\",\n",
            "          \"properties\": {}\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"function\": {\n",
            "        \"name\": \"create_contact\",\n",
            "        \"description\": \"Creates a contact in the phone's contact list.\",\n",
            "        \"parameters\": {\n",
            "          \"type\": \"OBJECT\",\n",
            "          \"properties\": {\n",
            "            \"email\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The email address of the contact.\"\n",
            "            },\n",
            "            \"first_name\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The first name of the contact.\"\n",
            "            },\n",
            "            \"last_name\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The last name of the contact.\"\n",
            "            },\n",
            "            \"phone_number\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The phone number of the contact.\"\n",
            "            }\n",
            "          },\n",
            "          \"required\": [\n",
            "            \"first_name\",\n",
            "            \"last_name\"\n",
            "          ]\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"function\": {\n",
            "        \"name\": \"show_map\",\n",
            "        \"description\": \"Shows a location on the map.\",\n",
            "        \"parameters\": {\n",
            "          \"type\": \"OBJECT\",\n",
            "          \"properties\": {\n",
            "            \"query\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The location to search for. May be the name of a place, a business, or an address.\"\n",
            "            }\n",
            "          },\n",
            "          \"required\": [\n",
            "            \"query\"\n",
            "          ]\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"function\": {\n",
            "        \"name\": \"create_calendar_event\",\n",
            "        \"description\": \"Creates a new calendar event.\",\n",
            "        \"parameters\": {\n",
            "          \"type\": \"OBJECT\",\n",
            "          \"properties\": {\n",
            "            \"title\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The title of the event.\"\n",
            "            },\n",
            "            \"datetime\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The date and time of the event in the format YYYY-MM-DDTHH:MM:SS.\"\n",
            "            }\n",
            "          },\n",
            "          \"required\": [\n",
            "            \"title\",\n",
            "            \"datetime\"\n",
            "          ]\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"function\": {\n",
            "        \"name\": \"turn_off_flashlight\",\n",
            "        \"description\": \"Turns the flashlight off.\",\n",
            "        \"parameters\": {\n",
            "          \"type\": \"OBJECT\",\n",
            "          \"properties\": {}\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"function\": {\n",
            "        \"name\": \"send_email\",\n",
            "        \"description\": \"Sends an email.\",\n",
            "        \"parameters\": {\n",
            "          \"type\": \"OBJECT\",\n",
            "          \"properties\": {\n",
            "            \"body\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The body of the email.\"\n",
            "            },\n",
            "            \"subject\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The subject of the email.\"\n",
            "            },\n",
            "            \"to\": {\n",
            "              \"type\": \"STRING\",\n",
            "              \"description\": \"The email address of the recipient.\"\n",
            "            }\n",
            "          },\n",
            "          \"required\": [\n",
            "            \"to\",\n",
            "            \"subject\"\n",
            "          ]\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"function\": {\n",
            "        \"name\": \"open_wifi_settings\",\n",
            "        \"description\": \"Opens the Wi-Fi settings.\",\n",
            "        \"parameters\": {\n",
            "          \"type\": \"OBJECT\",\n",
            "          \"properties\": {}\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"messages\": [\n",
            "    {\n",
            "      \"role\": \"developer\",\n",
            "      \"content\": \"Current date and time given in YYYY-MM-DDTHH:MM:SS format: 2024-07-09T20:42:38\\nDay of week is Tuesday\\nYou are a model that can do function calling with the following functions\\n\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"Please turn on the flashlight and also create a calendar event titled 'Follow-up with Ms. Patel' for July 15th, 2024 at 2:30 PM.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"assistant\",\n",
            "      \"tool_calls\": [\n",
            "        {\n",
            "          \"function\": {\n",
            "            \"name\": \"turn_on_flashlight\",\n",
            "            \"arguments\": {}\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"function\": {\n",
            "            \"name\": \"create_calendar_event\",\n",
            "            \"arguments\": {\n",
            "              \"title\": \"Follow-up with Ms. Patel\",\n",
            "              \"datetime\": \"2024-07-15T14:30:00\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from random import randint\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "data_file = hf_hub_download(repo_id=\"google/mobile-actions\", filename=\"dataset.jsonl\", repo_type=\"dataset\")\n",
        "dataset = load_dataset(\"text\", data_files=data_file, encoding=\"utf-8\")[\"train\"].shuffle()\n",
        "\n",
        "print(f\"\\n\\033[1mHere's an example from your dataset:\\033[0m \\n{json.dumps(json.loads(dataset[randint(0, len(dataset) - 1)]['text']), indent=2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PafivP8u1Gv9"
      },
      "source": [
        "## Process the dataset for training and evaluation\n",
        "\n",
        "Now that you've loaded your data, format the training dataset into [Prompt-completion](https://huggingface.co/docs/trl/main/en/dataset_formats#prompt-completion) format for more efficient training later (`completion_only_loss=True`). This means the model will only learn from the `completion` instead of the `prompt`.\n",
        "\n",
        "- `prompt` for the non-trainable parts\n",
        "- `completion` for the trainable parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VWz32s5h074E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8d80046d09fb41dc90c1e751e3585a9a",
            "5ffa28040b7342128766d519e2488f65",
            "a87475fa9d4942adb5aca4d73f2407dd",
            "826934538537420d9db7bc91c49e596c",
            "1b5dcf6096474425a000d58eda5fb2f1",
            "07e8012f61ab412d92706598b6c8c506",
            "9234fe652097401abcf7af02a0415b0c",
            "3b64f71d152f4f97bb47f155176be5cc",
            "4e30d43de4a24b3485cc602321421197",
            "8f7eb6e17ae643329cf48e02f3f5f1bb",
            "2811c865e2eb4bbaa8b3761e61234931"
          ]
        },
        "outputId": "47398d7b-2534-48cc-c295-b1f21e7afe9f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9654 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d80046d09fb41dc90c1e751e3585a9a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def apply_format(sample):\n",
        "  template_iputs = json.loads(sample['text'])\n",
        "\n",
        "  prompt_and_completion = tokenizer.apply_chat_template(\n",
        "    template_iputs['messages'],\n",
        "    tools=template_iputs['tools'],\n",
        "    tokenize=False,\n",
        "    # add_generation_prompt is False since we don't need model output after all\n",
        "    # messages.\n",
        "    add_generation_prompt=False)\n",
        "\n",
        "  prompt = tokenizer.apply_chat_template(\n",
        "    template_iputs['messages'][:-1],\n",
        "    tools=template_iputs['tools'],\n",
        "    tokenize=False,\n",
        "    # add_generation_prompt is True since we would like to include\n",
        "    # \"<start_of_turn>model\" in the prompt, if needed.\n",
        "    add_generation_prompt=True)\n",
        "\n",
        "  completion = prompt_and_completion[len(prompt):]\n",
        "\n",
        "  return {\n",
        "     \"prompt\": prompt,\n",
        "     \"completion\": completion,\n",
        "     \"split\": template_iputs[\"metadata\"],\n",
        "  }\n",
        "\n",
        "processed_dataset = dataset.map(apply_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YWf9Vlfm9tkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31d57d7-7c13-4ba8-a45c-19e2db3141a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mHere's an example from the formatted dataset:\u001b[0m\n",
            "{\n",
            "  \"text\": \"{\\\"metadata\\\": \\\"train\\\", \\\"tools\\\": [{\\\"function\\\": {\\\"name\\\": \\\"send_email\\\", \\\"description\\\": \\\"Sends an email.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {\\\"subject\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The subject of the email.\\\"}, \\\"to\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The email address of the recipient.\\\"}, \\\"body\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The body of the email.\\\"}}, \\\"required\\\": [\\\"to\\\", \\\"subject\\\"]}}}, {\\\"function\\\": {\\\"name\\\": \\\"turn_on_flashlight\\\", \\\"description\\\": \\\"Turns the flashlight on.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {}}}}, {\\\"function\\\": {\\\"name\\\": \\\"open_wifi_settings\\\", \\\"description\\\": \\\"Opens the Wi-Fi settings.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {}}}}, {\\\"function\\\": {\\\"name\\\": \\\"show_map\\\", \\\"description\\\": \\\"Shows a location on the map.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {\\\"query\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The location to search for. May be the name of a place, a business, or an address.\\\"}}, \\\"required\\\": [\\\"query\\\"]}}}, {\\\"function\\\": {\\\"name\\\": \\\"create_calendar_event\\\", \\\"description\\\": \\\"Creates a new calendar event.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {\\\"datetime\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The date and time of the event in the format YYYY-MM-DDTHH:MM:SS.\\\"}, \\\"title\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The title of the event.\\\"}}, \\\"required\\\": [\\\"title\\\", \\\"datetime\\\"]}}}, {\\\"function\\\": {\\\"name\\\": \\\"turn_off_flashlight\\\", \\\"description\\\": \\\"Turns the flashlight off.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {}}}}, {\\\"function\\\": {\\\"name\\\": \\\"create_contact\\\", \\\"description\\\": \\\"Creates a contact in the phone's contact list.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {\\\"first_name\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The first name of the contact.\\\"}, \\\"email\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The email address of the contact.\\\"}, \\\"phone_number\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The phone number of the contact.\\\"}, \\\"last_name\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The last name of the contact.\\\"}}, \\\"required\\\": [\\\"first_name\\\", \\\"last_name\\\"]}}}], \\\"messages\\\": [{\\\"role\\\": \\\"developer\\\", \\\"content\\\": \\\"Current date and time given in YYYY-MM-DDTHH:MM:SS format: 2024-09-18T15:45:22\\\\nDay of week is Wednesday\\\\nYou are a model that can do function calling with the following functions\\\\n\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"I need to set up a calendar reminder for a project review on September 25th at 3:30 PM, and make sure the flashlight is off since I don't need it anymore.\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"tool_calls\\\": [{\\\"function\\\": {\\\"name\\\": \\\"create_calendar_event\\\", \\\"arguments\\\": {\\\"title\\\": \\\"project review\\\", \\\"datetime\\\": \\\"2024-09-25T15:30:00\\\"}}}, {\\\"function\\\": {\\\"name\\\": \\\"turn_off_flashlight\\\", \\\"arguments\\\": {}}}]}]}\",\n",
            "  \"prompt\": \"<bos><start_of_turn>developer\\nCurrent date and time given in YYYY-MM-DDTHH:MM:SS format: 2024-09-18T15:45:22\\nDay of week is Wednesday\\nYou are a model that can do function calling with the following functions<start_function_declaration>declaration:send_email{description:<escape>Sends an email.<escape>,parameters:{properties:{body:{description:<escape>The body of the email.<escape>,type:<escape>STRING<escape>},subject:{description:<escape>The subject of the email.<escape>,type:<escape>STRING<escape>},to:{description:<escape>The email address of the recipient.<escape>,type:<escape>STRING<escape>}},required:[<escape>to<escape>,<escape>subject<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:turn_on_flashlight{description:<escape>Turns the flashlight on.<escape>,parameters:{type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:open_wifi_settings{description:<escape>Opens the Wi-Fi settings.<escape>,parameters:{type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:show_map{description:<escape>Shows a location on the map.<escape>,parameters:{properties:{query:{description:<escape>The location to search for. May be the name of a place, a business, or an address.<escape>,type:<escape>STRING<escape>}},required:[<escape>query<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:create_calendar_event{description:<escape>Creates a new calendar event.<escape>,parameters:{properties:{datetime:{description:<escape>The date and time of the event in the format YYYY-MM-DDTHH:MM:SS.<escape>,type:<escape>STRING<escape>},title:{description:<escape>The title of the event.<escape>,type:<escape>STRING<escape>}},required:[<escape>title<escape>,<escape>datetime<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:turn_off_flashlight{description:<escape>Turns the flashlight off.<escape>,parameters:{type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:create_contact{description:<escape>Creates a contact in the phone's contact list.<escape>,parameters:{properties:{email:{description:<escape>The email address of the contact.<escape>,type:<escape>STRING<escape>},first_name:{description:<escape>The first name of the contact.<escape>,type:<escape>STRING<escape>},last_name:{description:<escape>The last name of the contact.<escape>,type:<escape>STRING<escape>},phone_number:{description:<escape>The phone number of the contact.<escape>,type:<escape>STRING<escape>}},required:[<escape>first_name<escape>,<escape>last_name<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><end_of_turn>\\n<start_of_turn>user\\nI need to set up a calendar reminder for a project review on September 25th at 3:30 PM, and make sure the flashlight is off since I don't need it anymore.<end_of_turn>\\n<start_of_turn>model\\n\",\n",
            "  \"completion\": \"<start_function_call>call:create_calendar_event{datetime:<escape>2024-09-25T15:30:00<escape>,title:<escape>project review<escape>}<end_function_call><start_function_call>call:turn_off_flashlight{}<end_function_call><start_function_response>\",\n",
            "  \"split\": \"train\"\n",
            "}\n",
            "\n",
            "\u001b[1mThe longest example length is 4157 with 897 tokens. We need to set the max_length larger than the token count in SFTConfig below.\u001b[0m\n",
            "{\n",
            "  \"text\": \"{\\\"metadata\\\": \\\"train\\\", \\\"tools\\\": [{\\\"function\\\": {\\\"name\\\": \\\"open_wifi_settings\\\", \\\"description\\\": \\\"Opens the Wi-Fi settings.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {}}}}, {\\\"function\\\": {\\\"name\\\": \\\"turn_off_flashlight\\\", \\\"description\\\": \\\"Turns the flashlight off.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {}}}}, {\\\"function\\\": {\\\"name\\\": \\\"create_calendar_event\\\", \\\"description\\\": \\\"Creates a new calendar event.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {\\\"datetime\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The date and time of the event in the format YYYY-MM-DDTHH:MM:SS.\\\"}, \\\"title\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The title of the event.\\\"}}, \\\"required\\\": [\\\"title\\\", \\\"datetime\\\"]}}}, {\\\"function\\\": {\\\"name\\\": \\\"create_contact\\\", \\\"description\\\": \\\"Creates a contact in the phone's contact list.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {\\\"last_name\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The last name of the contact.\\\"}, \\\"email\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The email address of the contact.\\\"}, \\\"first_name\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The first name of the contact.\\\"}, \\\"phone_number\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The phone number of the contact.\\\"}}, \\\"required\\\": [\\\"first_name\\\", \\\"last_name\\\"]}}}, {\\\"function\\\": {\\\"name\\\": \\\"turn_on_flashlight\\\", \\\"description\\\": \\\"Turns the flashlight on.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {}}}}, {\\\"function\\\": {\\\"name\\\": \\\"show_map\\\", \\\"description\\\": \\\"Shows a location on the map.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {\\\"query\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The location to search for. May be the name of a place, a business, or an address.\\\"}}, \\\"required\\\": [\\\"query\\\"]}}}, {\\\"function\\\": {\\\"name\\\": \\\"send_email\\\", \\\"description\\\": \\\"Sends an email.\\\", \\\"parameters\\\": {\\\"type\\\": \\\"OBJECT\\\", \\\"properties\\\": {\\\"to\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The email address of the recipient.\\\"}, \\\"body\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The body of the email.\\\"}, \\\"subject\\\": {\\\"type\\\": \\\"STRING\\\", \\\"description\\\": \\\"The subject of the email.\\\"}}, \\\"required\\\": [\\\"to\\\", \\\"subject\\\"]}}}], \\\"messages\\\": [{\\\"role\\\": \\\"developer\\\", \\\"content\\\": \\\"Current date and time given in YYYY-MM-DDTHH:MM:SS format: 2025-11-24T12:55:01\\\\nDay of week is Monday\\\\nYou are a model that can do function calling with the following functions\\\\n\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"I need to create a calendar event titled \\\\\\\"Q4 Review Strategy Session\\\\\\\" for 2025-11-26T15:00:00, and simultaneously send an email to elena.vasiliev@corpmail.com with the subject \\\\\\\"Follow-up on Q4 Review Prep\\\\\\\" and the body \\\\\\\"Hi Elena, I've scheduled our follow-up meeting to discuss the Q4 review strategy. Please review the attached calendar invite. Let me know if you have any conflicts. Thanks.\\\\\\\"\\\\n\\\\nPlease schedule a calendar event titled \\\\\\\"Q4 Review Strategy Session\\\\\\\" for 2025-11-26 at 3:00 PM, and immediately send an email to elena.vasiliev@corpmail.com with the subject \\\\\\\"Follow-up on Q4 Review Prep\\\\\\\" and the body \\\\\\\"Hi Elena, I've scheduled our follow-up meeting to discuss the Q4 review strategy. Please review the attached calendar invite. Let me know if you have any conflicts. Thanks.\\\\\\\"\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"tool_calls\\\": [{\\\"function\\\": {\\\"name\\\": \\\"create_calendar_event\\\", \\\"arguments\\\": {\\\"title\\\": \\\"Q4 Review Strategy Session\\\", \\\"datetime\\\": \\\"2025-11-26T15:00:00\\\"}}}, {\\\"function\\\": {\\\"name\\\": \\\"send_email\\\", \\\"arguments\\\": {\\\"body\\\": \\\"Hi Elena, I've scheduled our follow-up meeting to discuss the Q4 review strategy. Please review the attached calendar invite. Let me know if you have any conflicts. Thanks.\\\", \\\"subject\\\": \\\"Follow-up on Q4 Review Prep\\\", \\\"to\\\": \\\"elena.vasiliev@corpmail.com\\\"}}}]}]}\",\n",
            "  \"prompt\": \"<bos><start_of_turn>developer\\nCurrent date and time given in YYYY-MM-DDTHH:MM:SS format: 2025-11-24T12:55:01\\nDay of week is Monday\\nYou are a model that can do function calling with the following functions<start_function_declaration>declaration:open_wifi_settings{description:<escape>Opens the Wi-Fi settings.<escape>,parameters:{type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:turn_off_flashlight{description:<escape>Turns the flashlight off.<escape>,parameters:{type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:create_calendar_event{description:<escape>Creates a new calendar event.<escape>,parameters:{properties:{datetime:{description:<escape>The date and time of the event in the format YYYY-MM-DDTHH:MM:SS.<escape>,type:<escape>STRING<escape>},title:{description:<escape>The title of the event.<escape>,type:<escape>STRING<escape>}},required:[<escape>title<escape>,<escape>datetime<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:create_contact{description:<escape>Creates a contact in the phone's contact list.<escape>,parameters:{properties:{email:{description:<escape>The email address of the contact.<escape>,type:<escape>STRING<escape>},first_name:{description:<escape>The first name of the contact.<escape>,type:<escape>STRING<escape>},last_name:{description:<escape>The last name of the contact.<escape>,type:<escape>STRING<escape>},phone_number:{description:<escape>The phone number of the contact.<escape>,type:<escape>STRING<escape>}},required:[<escape>first_name<escape>,<escape>last_name<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:turn_on_flashlight{description:<escape>Turns the flashlight on.<escape>,parameters:{type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:show_map{description:<escape>Shows a location on the map.<escape>,parameters:{properties:{query:{description:<escape>The location to search for. May be the name of a place, a business, or an address.<escape>,type:<escape>STRING<escape>}},required:[<escape>query<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:send_email{description:<escape>Sends an email.<escape>,parameters:{properties:{body:{description:<escape>The body of the email.<escape>,type:<escape>STRING<escape>},subject:{description:<escape>The subject of the email.<escape>,type:<escape>STRING<escape>},to:{description:<escape>The email address of the recipient.<escape>,type:<escape>STRING<escape>}},required:[<escape>to<escape>,<escape>subject<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><end_of_turn>\\n<start_of_turn>user\\nI need to create a calendar event titled \\\"Q4 Review Strategy Session\\\" for 2025-11-26T15:00:00, and simultaneously send an email to elena.vasiliev@corpmail.com with the subject \\\"Follow-up on Q4 Review Prep\\\" and the body \\\"Hi Elena, I've scheduled our follow-up meeting to discuss the Q4 review strategy. Please review the attached calendar invite. Let me know if you have any conflicts. Thanks.\\\"\\n\\nPlease schedule a calendar event titled \\\"Q4 Review Strategy Session\\\" for 2025-11-26 at 3:00 PM, and immediately send an email to elena.vasiliev@corpmail.com with the subject \\\"Follow-up on Q4 Review Prep\\\" and the body \\\"Hi Elena, I've scheduled our follow-up meeting to discuss the Q4 review strategy. Please review the attached calendar invite. Let me know if you have any conflicts. Thanks.\\\"<end_of_turn>\\n<start_of_turn>model\\n\",\n",
            "  \"completion\": \"<start_function_call>call:create_calendar_event{datetime:<escape>2025-11-26T15:00:00<escape>,title:<escape>Q4 Review Strategy Session<escape>}<end_function_call><start_function_call>call:send_email{body:<escape>Hi Elena, I've scheduled our follow-up meeting to discuss the Q4 review strategy. Please review the attached calendar invite. Let me know if you have any conflicts. Thanks.<escape>,subject:<escape>Follow-up on Q4 Review Prep<escape>,to:<escape>elena.vasiliev@corpmail.com<escape>}<end_function_call><start_function_response>\",\n",
            "  \"split\": \"train\"\n",
            "}\n",
            "\n",
            "\u001b[1mUsing max_token_count of 997 (= 897 + 100) for training below.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title Review the processed dataset\n",
        "\n",
        "print(\"\\033[1mHere's an example from the formatted dataset:\\033[0m\")\n",
        "print(json.dumps(processed_dataset[randint(0, len(processed_dataset) - 1)], indent=2))\n",
        "\n",
        "longest_example = max(processed_dataset, key=lambda example: len(example['prompt'] + example['completion']))\n",
        "longest_example_token_count = len(tokenizer.tokenize(longest_example['prompt'] + longest_example['completion']))\n",
        "\n",
        "print(f\"\\n\\033[1mThe longest example length is {len(longest_example['prompt'] + longest_example['completion'])} with {longest_example_token_count} tokens. We need to set the max_length larger than the token count in SFTConfig below.\\033[0m\")\n",
        "print(json.dumps(longest_example, indent=2))\n",
        "\n",
        "max_token_count = longest_example_token_count + 100\n",
        "print(f\"\\n\\033[1mUsing max_token_count of {max_token_count} (= {longest_example_token_count} + 100) for training below.\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2QPMjN_vwQf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "80eec03bac484a84b4c1a06098897179",
            "9985d0bd4b4946b4a4f48143d8d252f1",
            "2e5d8404df91478bb8f15860f49ed795",
            "73c5b674d8b445d6ab4c23ac54e3d937",
            "925bcfb33aeb42299df5083e813b2c7e",
            "b8d5cd1d90084c9c81e3cf8c56b9fc10",
            "6bb7b5b8c8b04334a7b07c93557b8816",
            "2c619e61d12a4f7d92f39d63f7416ea1",
            "ae84b60a431c4da6be22321fad4d69bf",
            "bb3ab909f7b442b690cc1d9132b3ffe2",
            "4f50bdef63d64396888536910140104d",
            "855f09cd58d94ef48d68b16f6e896b52",
            "db41fc74b27e422f8a08729acdb06c55",
            "cc43ef1d0fd94c4a83087c61595e3cc3",
            "f8afc06b8726412fb29f7d27ddf8b0e3",
            "44fa6fb5de504c3c8fd000d0dbbc3b24",
            "26ce90dcbd2141258d8e013fee936f83",
            "1cbf277fd5ef43ebbe419478d6327f45",
            "d020672060e34e7c9dd41475570e72a4",
            "fdee2521bd1d40bf98f839fc7099677c",
            "aea9a2d8441640ae90bfcae942baf6bb",
            "6475852034d34a548e812fd7e0c7b02e"
          ]
        },
        "outputId": "e76df379-c6b6-4e9e-e5d9-32d4fa1b09f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/9654 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80eec03bac484a84b4c1a06098897179"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/9654 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "855f09cd58d94ef48d68b16f6e896b52"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Prepare train and eval dataset.\n",
        "\n",
        "train_dataset = processed_dataset.filter(lambda example: example['split'] == 'train')\n",
        "eval_dataset = processed_dataset.filter(lambda example: example['split'] == 'eval')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3w3b9-O4fDz"
      },
      "source": [
        "## Recommended: Test the base model\n",
        "\n",
        "Now, we have loaded both the base model and the dataset. Let's first check how the base model's ability to respond to  \n",
        "a random sample.\n",
        "\n",
        "Try testing it a few times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7S8X9LBKYD3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125214df-5d46-4977-a840-47b068558f01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mPrompt:\u001b[0m Schedule a \"team meeting\" tomorrow at 4pm.\n",
            "\n",
            "\u001b[1mBase model output:\u001b[0m I apologize, but I cannot assist with scheduling meetings. My current tools are designed for managing calendar events and contact management, and I cannot access or manage meeting schedules.\n"
          ]
        }
      ],
      "source": [
        "#@title Test with a prompt\n",
        "\n",
        "from transformers import pipeline\n",
        "from random import randint\n",
        "import re\n",
        "\n",
        "# Create a transformers inference pipeline\n",
        "pipe = pipeline(\"text-generation\", model=gemma_model, tokenizer=tokenizer)\n",
        "\n",
        "user_prompt = \"Schedule a \\\"team meeting\\\" tomorrow at 4pm.\"  #@param {type:\"string\"}\n",
        "messages = [\n",
        "    {\"role\": \"developer\", \"content\": \"Current date and time given in YYYY-MM-DDTHH:MM:SS format: 2024-11-15T05:59:00. You are a model that can do function calling with the following functions\"},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "]\n",
        "\n",
        "# Reuse the tools from the sample\n",
        "tools = json.loads(dataset[0]['text'])['tools']\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tools=tools,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True)\n",
        "\n",
        "print(f\"\\n\\033[1mPrompt:\\033[0m {user_prompt}\")\n",
        "output = pipe(prompt, max_new_tokens=max_token_count)\n",
        "model_output = output[0]['generated_text'][len(prompt):].strip()\n",
        "\n",
        "print(f\"\\n\\033[1mBase model output:\\033[0m {model_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNfNON0yBJlg"
      },
      "source": [
        "Note that how the base model is unable to successfully call the `create_calendar_event` function for this prompt.\n",
        "\n",
        "Now, we will pick a sample from the training dataset and see how it performs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvgTeVQCAcxe"
      },
      "source": [
        "## Test with training dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u8L0_INJyUok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4d6b1c-db75-4db8-d307-78e9b0321190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mInput prompt\u001b[0m   : <bos><start_of_turn>developer\n",
            "Current date and time given in YYYY-MM-DDTHH:MM:SS format: 2024-11-28T17:18:08\n",
            "Day of week is Thursday\n",
            "You are a model that can do function calling with the following functions<start_function_declaration>declaration:create_contact{description:<escape>Creates a contact in the phone's contact list.<escape>,parameters:{properties:{email:{description:<escape>The email address of the contact.<escape>,type:<escape>STRING<escape>},first_name:{description:<escape>The first name of the contact.<escape>,type:<escape>STRING<escape>},last_name:{description:<escape>The last name of the contact.<escape>,type:<escape>STRING<escape>},phone_number:{description:<escape>The phone number of the contact.<escape>,type:<escape>STRING<escape>}},required:[<escape>first_name<escape>,<escape>last_name<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:show_map{description:<escape>Shows a location on the map.<escape>,parameters:{properties:{query:{description:<escape>The location to search for. May be the name of a place, a business, or an address.<escape>,type:<escape>STRING<escape>}},required:[<escape>query<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:open_wifi_settings{description:<escape>Opens the Wi-Fi settings.<escape>,parameters:{type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:create_calendar_event{description:<escape>Creates a new calendar event.<escape>,parameters:{properties:{datetime:{description:<escape>The date and time of the event in the format YYYY-MM-DDTHH:MM:SS.<escape>,type:<escape>STRING<escape>},title:{description:<escape>The title of the event.<escape>,type:<escape>STRING<escape>}},required:[<escape>title<escape>,<escape>datetime<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:send_email{description:<escape>Sends an email.<escape>,parameters:{properties:{body:{description:<escape>The body of the email.<escape>,type:<escape>STRING<escape>},subject:{description:<escape>The subject of the email.<escape>,type:<escape>STRING<escape>},to:{description:<escape>The email address of the recipient.<escape>,type:<escape>STRING<escape>}},required:[<escape>to<escape>,<escape>subject<escape>],type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:turn_off_flashlight{description:<escape>Turns the flashlight off.<escape>,parameters:{type:<escape>OBJECT<escape>}}<end_function_declaration><start_function_declaration>declaration:turn_on_flashlight{description:<escape>Turns the flashlight on.<escape>,parameters:{type:<escape>OBJECT<escape>}}<end_function_declaration><end_of_turn>\n",
            "<start_of_turn>user\n",
            "Turn on the flashlight and create a new contact named Elena Rossi with the phone number 555-0192 and email address elena.rossi@mailcorp.it.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n",
            "\n",
            "\u001b[1mExpected output\u001b[0m: <start_function_call>call:turn_on_flashlight{}<end_function_call><start_function_call>call:create_contact{email:<escape>elena.rossi@mailcorp.it<escape>,first_name:<escape>Elena<escape>,last_name:<escape>Rossi<escape>,phone_number:<escape>555-0192<escape>}<end_function_call><start_function_response>\n",
            "\n",
            "\u001b[1mActual output\u001b[0m  : <start_function_call>call:turn_on_flashlight{}<end_function_call><start_function_call>call:create_contact{first_name:<escape>Elena<escape>,last_name:<escape>Rossi<escape>,phone_number:<escape>555-0192<escape>,email:<escape>elena.rossi@mailcorp.it<escape>}<end_function_call><start_function_response>\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from random import randint\n",
        "import re\n",
        "\n",
        "# Create a transformers inference pipeline\n",
        "pipe = pipeline(\"text-generation\", model=gemma_model, tokenizer=tokenizer)\n",
        "\n",
        "# Select a random sample from the test dataset\n",
        "rand_idx = randint(0, len(train_dataset) - 1)\n",
        "test_sample = train_dataset[rand_idx]\n",
        "\n",
        "input_prompt = test_sample['prompt']\n",
        "expected_output = test_sample['completion']\n",
        "\n",
        "# Generate the output\n",
        "output = pipe(input_prompt, max_new_tokens=max_token_count, skip_special_tokens=False)\n",
        "actual_output = output[0]['generated_text'][len(input_prompt):].strip()\n",
        "\n",
        "print(f\"\\n\\033[1mInput prompt\\033[0m   : {input_prompt}\")\n",
        "print(f\"\\n\\033[1mExpected output\\033[0m: {expected_output}\")\n",
        "print(f\"\\n\\033[1mActual output\\033[0m  : {actual_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph26HDJgua3W"
      },
      "source": [
        "The base model output may not meet your expectationsand that's okay!\n",
        "\n",
        "FunctionGemma 270M was designed for task specialization, which means it can improve performance for specific tasks when trained with representative examples. Let's fine-tune the model for more reliable outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbd9fc1b"
      },
      "source": [
        "## Fine-tune the model\n",
        "\n",
        "Hugging Face [TRL](https://huggingface.co/docs/trl/index) provides tools for training and fine-tuning LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BJFoOdL0y8w"
      },
      "source": [
        "### Configure the tuning job\n",
        "Define the training configuration for the FunctionGemma base model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qiIj1ADc-exw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d0c438-45e9-42db-8358-70c3675025e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training configured\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "from trl import SFTConfig\n",
        "\n",
        "output_dir = \"/content/mobile-actions-functiongemma\"  # Where to save your fine-tuned checkpoints\n",
        "tokenizer = AutoTokenizer.from_pretrained(gemma_model)\n",
        "\n",
        "args = SFTConfig(\n",
        "    output_dir=output_dir,                            # Directory to save adapters\n",
        "    num_train_epochs=2,                               # Number of training epochs\n",
        "    per_device_train_batch_size=4,                    # Batch size per device during training\n",
        "    gradient_accumulation_steps=8,                    # Gradient accumulation during training\n",
        "    logging_strategy=\"steps\",                         # Log every steps\n",
        "    eval_strategy=\"steps\",                            # Evaluate loss metrics based on steps\n",
        "    eval_steps=50,                                    # Evaluate loss metrics every 50 steps\n",
        "    logging_steps=50,                                 # Log loss metrics every 50 steps\n",
        "    save_strategy=\"epoch\",                            # Save checkpoint every epoch\n",
        "    learning_rate=1e-5,                               # Learning rate,\n",
        "    lr_scheduler_type=\"cosine\",                       # Cosine scheduler is often better for full FT\n",
        "    max_length=max_token_count,                       # Max sequence length for model and packing of the dataset\n",
        "    gradient_checkpointing=True,                      # Use gradient checkpointing to save memory\n",
        "    packing=False,                                    # Groups multiple samples in the dataset into a single sequence\n",
        "    optim=\"adamw_torch_fused\",                        # Use fused adamw optimizer\n",
        "    bf16=True,                                        # Use bf16 for mixed precision training\n",
        "    completion_only_loss=True,                        # Train on completion only to improve quality\n",
        "    report_to=\"none\"                                  # No reporting.\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    gemma_model,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        "    attn_implementation='eager')\n",
        "\n",
        "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "print(\"Training configured\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(base_model)\n",
        "\n",
        "#return layers that are 'Linear' (the ones that should be targeted by LoRA for best performance)\n",
        "def find_target_modules(model):\n",
        "    unique_layers = set()\n",
        "\n",
        "    for name, module in model.named_modules():\n",
        "        if \"Linear\" in str(type(module)) and \"lm_head\" not in name:\n",
        "            layer_type = name.split('.')[-1]\n",
        "            unique_layers.add(layer_type)\n",
        "\n",
        "    return list(unique_layers)\n",
        "\n",
        "modules = find_target_modules(base_model)\n",
        "print(modules)"
      ],
      "metadata": {
        "id": "cvxMV5D8AXAJ",
        "outputId": "e7760107-dd54-48aa-ff44-ec1cb06d5351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemma3ForCausalLM(\n",
            "  (model): Gemma3TextModel(\n",
            "    (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 640, padding_idx=0)\n",
            "    (layers): ModuleList(\n",
            "      (0-17): 18 x Gemma3DecoderLayer(\n",
            "        (self_attn): Gemma3Attention(\n",
            "          (q_proj): Linear(in_features=640, out_features=1024, bias=False)\n",
            "          (k_proj): Linear(in_features=640, out_features=256, bias=False)\n",
            "          (v_proj): Linear(in_features=640, out_features=256, bias=False)\n",
            "          (o_proj): Linear(in_features=1024, out_features=640, bias=False)\n",
            "          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
            "          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
            "        )\n",
            "        (mlp): Gemma3MLP(\n",
            "          (gate_proj): Linear(in_features=640, out_features=2048, bias=False)\n",
            "          (up_proj): Linear(in_features=640, out_features=2048, bias=False)\n",
            "          (down_proj): Linear(in_features=2048, out_features=640, bias=False)\n",
            "          (act_fn): GELUTanh()\n",
            "        )\n",
            "        (input_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
            "        (post_attention_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
            "        (pre_feedforward_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
            "        (post_feedforward_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
            "      )\n",
            "    )\n",
            "    (norm): Gemma3RMSNorm((640,), eps=1e-06)\n",
            "    (rotary_emb): Gemma3RotaryEmbedding()\n",
            "    (rotary_emb_local): Gemma3RotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=640, out_features=262144, bias=False)\n",
            ")\n",
            "['k_proj', 'o_proj', 'v_proj', 'gate_proj', 'q_proj', 'down_proj', 'up_proj']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=16, # how much extra knowledge - more computation\n",
        "    lora_alpha=32, # how much influence the extra layers have on the model\n",
        "    lora_dropout=0.1, # randomly ignore some LoRA parameters during training to prevent overfitting\n",
        "    bias=\"none\", # this is usually only worth trying when we are fine-tuning for a very different task/domain\n",
        "    target_modules=modules,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "print(f\"Before adapter parameters: {base_model.num_parameters()}\")\n",
        "model = get_peft_model(base_model, peft_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKdfQXUx_Gw8",
        "outputId": "fb35bbbd-ea42-40fc-9c65-19a2d7e99939"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before adapter parameters: 268098176\n",
            "trainable params: 3,796,992 || all params: 271,895,168 || trainable%: 1.3965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd88e798"
      },
      "source": [
        "### Start training\n",
        "\n",
        "`SFTTrainer` tokenizes the datasets and trains the base model using the hyperparameters from the previous step.\n",
        "\n",
        "The training time varies based on a range of factors, such as the size of your dataset or number of epochs. Using a A100 GPU, this takes about 8 minutes for 1 epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WqacJNeU9v7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716,
          "referenced_widgets": [
            "cf392075ed3f401eaa55311f56029c4c",
            "4492bb93d5c54593853517bd37ede31a",
            "79c56fca027c4b44bb403beb1c1acb85",
            "9150d9d5181c4dc6a32be69a287a62e3",
            "48fe605f86ed419c83309b5e9a91b876",
            "07ea87d5efc343e19523125abdcdc69b",
            "814b4e0491cf48ffb6d615623a527273",
            "31268130e4834d2c8be58a1ca65d491c",
            "d947fcd02fcc47c48761f093ce9fa53d",
            "8c74b5826d814b19a9eb6db3950c701f",
            "59701d51df4f4cd5b9f6ead462a3831f",
            "3179477a077e42a19161c51b81f12361",
            "e6bc25edf34e462c839886f523645f21",
            "9189ded7cbae48b58ce83cf44a9cd2a3",
            "577ab9fb6e2449fb831f48b7995d04d0",
            "2e18c3382d75486ab2051da348c9871f",
            "a631d9b202a04887a8b50854cefb0d06",
            "3066dcb3bc6b46fe805ed75051fbdc8f",
            "10b6df3c79414365af117b57fee4ba42",
            "53e82cab04da4a52ae0fce0d347b3ba4",
            "5cde938b2cde473a92c76d1282becc22",
            "abe044d423ba4977aa59198c359b704d",
            "057e930576b54b93bc47c44617d111da",
            "e4c9229302444a3e921c9775f587ad74",
            "b06421929c6348888247c159b34cbbed",
            "dac6131e21094e69b976e38f0591e829",
            "8e1648e6e66a4cd0aeda87fdce506be3",
            "b70c821bf3444af987048e8c3ce0bf44",
            "fe0a6db6bb264c5e99df64b6f1930707",
            "961167ebdaac40f6aa212526d0ba41c8",
            "c26a04a1727547a9b86b9fca9378d9f3",
            "95278ec875754236882a6c376408a174",
            "6b86c9d97cf74b1eb9be717548a7d6fd",
            "dc0a70736eeb43d695ff6d402bc680a2",
            "a5ca0b3070bc448086cc44788a612b3d",
            "2becf97bf0014e20aba928f3786c1637",
            "333480bf34c04a639a3773d8c72e1c27",
            "0a41924ce0584068aca717e821c4d6f1",
            "ffa45f545da7478f9e72736a55946a59",
            "2b796c73bd144ce9920d4e9236901236",
            "a0440d6b52dc48d2b2cbc6ee3dbdacf2",
            "39ff2efdea3244f597a00c7b2d7b6237",
            "f16e9584ccc546bd900ae440ebd4fa31",
            "8ac5a38f5ee4463d93cc6c1d4dbf452c",
            "4d7a58e102b44c50bfe1c521619fa0da",
            "e16035f600b045f2834c4dbe83438f82",
            "8de7b12c5e094a3e903d50bdb19ce67a",
            "d8924ab3e108476e838a264a1bdba900",
            "a5f29223d1564b17a460d48fe9f206b9",
            "021f97c3652e48bea6a76f92a0d14cca",
            "79af8d8dfae142ad8f0722fd0a791d32",
            "d85773d49a89495087e5dfc456f50379",
            "ffacb061524e42718b5f21da5266407c",
            "4edc7339a5ad4cd2a263a6f711105172",
            "04ff538b5f6941988cb9bac0b5cb5b34"
          ]
        },
        "outputId": "8e2ecc28-3404-45d7-e416-6bafcde4676b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/8693 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf392075ed3f401eaa55311f56029c4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/8693 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3179477a077e42a19161c51b81f12361"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding EOS to eval dataset:   0%|          | 0/961 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "057e930576b54b93bc47c44617d111da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing eval dataset:   0%|          | 0/961 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc0a70736eeb43d695ff6d402bc680a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating eval dataset:   0%|          | 0/961 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d7a58e102b44c50bfe1c521619fa0da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 0}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 51/544 18:26 < 3:05:33, 0.04 it/s, Epoch 0.18/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 5.55 GiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 GiB is free. Process 99277 has 10.62 GiB memory in use. Of the allocated memory 9.40 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4244516742.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2754\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps_in_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2756\u001b[0;31m                         self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2757\u001b[0m                             \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m                             \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3219\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4489\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4490\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4491\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4684\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4685\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4686\u001b[0m             \u001b[0mmain_input_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main_input_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4687\u001b[0m             inputs_decode = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4900\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4901\u001b[0m                         \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_num_items_in_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4902\u001b[0;31m                         loss, outputs = self.compute_loss(\n\u001b[0m\u001b[1;32m   4903\u001b[0m                             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4904\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;31m# If not set, defaults from model config and may warn since cache isn't compatible with gradient checkpointing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_cache\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         (loss, outputs) = super().compute_loss(\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4108\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4109\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4110\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4111\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4112\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     decorate_autocast.__script_unsupported = (  # type: ignore[attr-defined]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         return CausalLMOutputWithPast(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/loss/loss_utils.py\u001b[0m in \u001b[0;36mForCausalLMLoss\u001b[0;34m(logits, labels, vocab_size, num_items_in_batch, ignore_index, shift_labels, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Enable model parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mshift_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/loss/loss_utils.py\u001b[0m in \u001b[0;36mfixed_cross_entropy\u001b[0;34m(source, target, num_items_in_batch, ignore_index, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> torch.Tensor:\n\u001b[1;32m     35\u001b[0m     \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sum\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# just in case users pass an int for num_items_in_batch, which could be the case for custom trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3459\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.55 GiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 GiB is free. Process 99277 has 10.62 GiB memory in use. Of the allocated memory 9.40 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "# Train and save the fine-tuned model\n",
        "trainer = SFTTrainer(\n",
        "    model=base_model,\n",
        "    #peft_config=peft_config,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Fine-tuned model saved to {output_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDvGlb5xO34z"
      },
      "source": [
        "The weights for each training checkpoint (epoch) will be saved in your temporary Colab session storage. Now, you can evaluate the training and validation loss metrics to choose which checkpoint to for the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xll8zZ3_u8Mt"
      },
      "source": [
        "### Plot training results\n",
        "To evaluate the model, you can plot the training and validation losses using Matplotlib to visualize these metrics over training steps or epochs. This helps monitor the training process and make informed decisions about which hyperparameters to adjust."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPN-DTopaUIy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Access the log history\n",
        "log_history = trainer.state.log_history\n",
        "\n",
        "# Extract training / validation loss\n",
        "train_losses = [log[\"loss\"] for log in log_history if \"loss\" in log]\n",
        "epoch_train = [log[\"epoch\"] for log in log_history if \"loss\" in log]\n",
        "eval_losses = [log[\"eval_loss\"] for log in log_history if \"eval_loss\" in log]\n",
        "epoch_eval = [log[\"epoch\"] for log in log_history if \"eval_loss\" in log]\n",
        "\n",
        "# Plot the training loss\n",
        "plt.plot(epoch_train, train_losses, label=\"Training Loss\")\n",
        "plt.plot(epoch_eval, eval_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss per Epoch\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf86e31d"
      },
      "source": [
        "### Test the fine-tuned model\n",
        "\n",
        "Let's compare your fine-tuned model performance against the base model! Test a few inputs by updating `user_prompt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28R3pRN_hai7"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Create Transformers inference pipeline\n",
        "trained_model = AutoModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "pipe = pipeline(\"text-generation\", model=trained_model, tokenizer=tokenizer)\n",
        "pipe_base = pipeline(\"text-generation\", model=gemma_model, device_map=\"auto\")\n",
        "\n",
        "# Test a prompt\n",
        "user_prompt = \"Schedule a \\\"team meeting\\\" tomorrow at 4pm.\"  #@param {type:\"string\"}\n",
        "messages = [\n",
        "    {\"role\": \"developer\", \"content\": \"Current date and time given in YYYY-MM-DDTHH:MM:SS format: 2024-11-15T05:59:00. You are a model that can do function calling with the following functions\"},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "]\n",
        "\n",
        "# Reuse the tools from the sample\n",
        "tools = json.loads(dataset[0]['text'])['tools']\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tools=tools,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True)\n",
        "\n",
        "print(f\"\\n\\033[1mPrompt:\\033[0m {prompt}\")\n",
        "output = pipe(prompt, max_new_tokens=max_token_count)\n",
        "output_base = pipe_base(prompt, max_new_tokens=max_token_count)\n",
        "model_output = output[0]['generated_text'][len(prompt):].strip()\n",
        "model_output_base = output_base[0]['generated_text'][len(prompt):].strip()\n",
        "\n",
        "print(f\"\\n\\033[1mFine-tuned model output:\\033[0m {model_output}\")\n",
        "\n",
        "print(f\"\\n\\033[1mBase model output:\\033[0m       {model_output_base}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmpAI15UeGcs"
      },
      "source": [
        "### Evaluate the fine-tuned model\n",
        "\n",
        "Evaluating a fine-tuned model is essential to ensure that the process actually improved the model's performance without introducing new issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O6HmcMawflSP"
      },
      "outputs": [],
      "source": [
        "#@title Helper functions for evaluation\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def extract_function_call(model_output):\n",
        "    \"\"\"\n",
        "    Parses a string containing specific function call markers and returns\n",
        "    a list of function call objects. Here is an example of the obejct:\n",
        "\n",
        "    ```\n",
        "    <start_function_call>call:open_map{query:<escape>San Francisco<escape>}<end_function_call>\n",
        "    ```\n",
        "\n",
        "    Args:\n",
        "        model_output (str): The model output string.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries representing the function calls.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Pattern to extract the full content of a single function call\n",
        "    # Flags: DOTALL allows matching across newlines if necessary\n",
        "    call_pattern = r\"<start_function_call>(.*?)<end_function_call>\"\n",
        "    raw_calls = re.findall(call_pattern, model_output, re.DOTALL)\n",
        "\n",
        "    for raw_call in raw_calls:\n",
        "        # Check if the content starts with 'call:'\n",
        "        if not raw_call.strip().startswith(\"call:\"):\n",
        "            continue\n",
        "\n",
        "        # Extract function name\n",
        "        # Expected format: call:func_name{...}\n",
        "        try:\n",
        "            # Split only on the first brace to separate name and args\n",
        "            pre_brace, args_segment = raw_call.split(\"{\", 1)\n",
        "\n",
        "            function_name = pre_brace.replace(\"call:\", \"\").strip()\n",
        "\n",
        "            # Remove the trailing closing brace '}'\n",
        "            args_content = args_segment.strip()\n",
        "            if args_content.endswith(\"}\"):\n",
        "                args_content = args_content[:-1]\n",
        "\n",
        "            arguments = {}\n",
        "\n",
        "            # Pattern to extract arguments\n",
        "            # Looks for: key:<escape>value<escape>\n",
        "            # The key pattern [^:,]* ensures we don't accidentally eat previous commas\n",
        "            arg_pattern = r\"(?P<key>[^:,]*?):<escape>(?P<value>.*?)<escape>\"\n",
        "\n",
        "            arg_matches = re.finditer(arg_pattern, args_content, re.DOTALL)\n",
        "\n",
        "            for match in arg_matches:\n",
        "                key = match.group(\"key\").strip()\n",
        "                value = match.group(\"value\")\n",
        "                arguments[key] = value\n",
        "\n",
        "            results.append({\n",
        "                \"function\": {\n",
        "                    \"name\": function_name,\n",
        "                    \"arguments\": arguments\n",
        "                }\n",
        "            })\n",
        "\n",
        "        except ValueError:\n",
        "            # Handles cases where syntax might be malformed (e.g., missing '{')\n",
        "            continue\n",
        "\n",
        "    return results\n",
        "\n",
        "def extract_text(model_output):\n",
        "    \"\"\"\n",
        "    Extracts text content and removing the <end_of_turn> marker.\n",
        "\n",
        "    Args:\n",
        "        model_output (str): The model output string.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned text.\n",
        "    \"\"\"\n",
        "    if not model_output or model_output.startswith(\"<start_function_call>\"):\n",
        "        return None\n",
        "    return model_output.replace(\"<end_of_turn>\", \"\").strip()\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "\n",
        "def get_eval_logs(dataset, pipe):\n",
        "  batch_size = 1\n",
        "  logs = []\n",
        "  # Select a random sample from the test dataset\n",
        "  for i, output in enumerate(pipe(KeyDataset(dataset, \"prompt\"), batch_size=batch_size)):\n",
        "    orig_data = dataset[i]['text']\n",
        "    messages = json.loads(orig_data)['messages']\n",
        "    user_message = messages[1]\n",
        "    assistant_first_message = messages[2]\n",
        "    input_prompt = dataset[i]['prompt']\n",
        "    # Generate the output\n",
        "    model_output_only = output[0]['generated_text'][len(input_prompt):].strip()\n",
        "\n",
        "    logs.append(\n",
        "        {\n",
        "            # The original user prompt/query.\n",
        "            \"user\": user_message['content'],\n",
        "\n",
        "            # List of ground truth function call objects.\n",
        "            \"target_fc\": assistant_first_message.get('tool_calls', []),\n",
        "\n",
        "            # Ground truth text response.\n",
        "            \"target_text\": assistant_first_message.get('content'),\n",
        "\n",
        "            # List of model-generated function call objects.\n",
        "            \"output_fc\": extract_function_call(model_output_only),\n",
        "\n",
        "            # Model-generated text response.\n",
        "            \"output_text\": extract_text(model_output_only),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if (i + 1) % batch_size == 0:\n",
        "      print(f\"Eval process: {(i + 1) * 100.0 / len(dataset):.2f}%\")\n",
        "  return logs\n",
        "\n",
        "def get_scored_data_frame(dataset, pipe):\n",
        "  logs = get_eval_logs(dataset, pipe)\n",
        "  logs_df = pd.DataFrame.from_records(logs)\n",
        "\n",
        "  scored = pd.DataFrame()\n",
        "  scored['user'] = logs_df['user']\n",
        "  scored['target_names'] = logs_df['target_fc'].apply(lambda x: [fc['function']['name'] for fc in x])\n",
        "  scored['output_names'] = logs_df['output_fc'].apply(lambda x: [fc['function']['name'] for fc in x])\n",
        "  scored[\"target_arguments\"] = logs_df['target_fc'].apply(lambda x: [dict(sorted(fc['function']['arguments'].items())) for fc in x])\n",
        "  scored[\"output_arguments\"] = logs_df['output_fc'].apply(lambda x: [dict(sorted(fc['function']['arguments'].items())) for fc in x])\n",
        "  scored['target_text'] = logs_df['target_text']\n",
        "  scored['output_text'] = logs_df['output_text']\n",
        "  scored[\"correct_names\"] = scored[\"target_names\"] == scored[\"output_names\"]\n",
        "  scored[\"correct_arguments\"] = scored[\"target_arguments\"] == scored[\"output_arguments\"]\n",
        "  scored[\"correct\"] = scored[\"correct_names\"] & scored[\"correct_arguments\"]\n",
        "\n",
        "  return scored\n",
        "\n",
        "def review(scored):\n",
        "  scored[\"incorrect_names\"] = scored[\"target_names\"] != scored[\"output_names\"]\n",
        "  scored[\"incorrect_arguments\"] = scored[\"target_arguments\"] != scored[\"output_arguments\"]\n",
        "  scored[\"incorrect\"] = scored[\"incorrect_names\"] | scored[\"incorrect_arguments\"]\n",
        "\n",
        "  for index, row in scored[scored[\"incorrect\"]].iterrows():\n",
        "    print(f\"\\033[1mSample #{index} prompt  \\033[0m: {row[\"user\"]}\")\n",
        "    print(f\"\\033[1mSample #{index} expected\\033[0m: {row[\"target_names\"]}, {row[\"target_arguments\"]}\")\n",
        "    print(f\"\\033[1mSample #{index} actual  \\033[0m: {row[\"output_names\"]}, {row[\"output_arguments\"]}\")\n",
        "    print(\"---------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eGq4ZsjjoTl"
      },
      "outputs": [],
      "source": [
        "#@title Evaluate the base model\n",
        "\n",
        "base_scored = get_scored_data_frame(\n",
        "    eval_dataset,\n",
        "    pipeline(\"text-generation\", model=gemma_model, device_map=\"auto\", temperature = 0.001),\n",
        ")\n",
        "\n",
        "base_scored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocOK88aEG6R6"
      },
      "outputs": [],
      "source": [
        "#@title Evaluate the fine-tuned model\n",
        "\n",
        "from transformers import pipeline\n",
        "from random import randint\n",
        "import re\n",
        "\n",
        "# Create a transformers inference pipeline\n",
        "trained_model = AutoModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "trained_scored = get_scored_data_frame(\n",
        "    eval_dataset,\n",
        "    pipeline(\"text-generation\", model=trained_model, tokenizer=tokenizer, temperature = 0.001)\n",
        ")\n",
        "\n",
        "trained_scored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMY1P8Rtyopt"
      },
      "outputs": [],
      "source": [
        "#@title Compare the score of the base and fine-tuned models\n",
        "\n",
        "# Optional: save the score in json file\n",
        "trained_scored.to_json('scored_df_20251215_trained.json')\n",
        "base_scored.to_json('scored_df_20251215_base.json')\n",
        "\n",
        "print(f\"\\033[1mBase model score\\033[0m       : {base_scored[\"correct\"].mean()}\")\n",
        "print(f\"\\033[1mFine-tuned model score\\033[0m : {trained_scored[\"correct\"].mean()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f-3QvCShs5a"
      },
      "source": [
        "## Review what are not matching\n",
        "\n",
        "The score about tell how much eval data get exactly correct function calls. It gives the lower bound of correctness. Some output might not match the eval date but still acceptable. For example, the `show_map` function call below:\n",
        "\n",
        "* show_map:{'query': 'Maison Marulaz, Besanon, France'}\n",
        "* show_map:{'query': 'Maison Marulaz in Besanon, France'}\n",
        "\n",
        "Let's take a look at the eval date without exact match. Many of them could also be acceptable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3-Iwa09zC_K"
      },
      "outputs": [],
      "source": [
        "review(trained_scored)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86qPcFbHH_kh"
      },
      "source": [
        "Does the model call the function you'd expect?\n",
        "\n",
        "If you're not getting the results you want, you can try [using different hyperparameters](#scrollTo=-BJFoOdL0y8w) to train the model, or updating your training dataset to contain more representative examples.\n",
        "\n",
        "Once you're happy with the results, you can save your model to Hugging Face Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H12D9g4X_peV"
      },
      "source": [
        "## Save your model and upload to Hugging Face Hub\n",
        "**You now have a customized FunctionGemma 270M model! **\n",
        "\n",
        "Upload it to a repository on Hugging Face Hub so you easily share your model or access it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbeyDcpwi4IB"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import ModelCard, ModelCardData, whoami\n",
        "\n",
        "trained_model = AutoModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "#@markdown Name your model\n",
        "model_name = \"mobile-actions\"    #@param {type:\"string\"}\n",
        "\n",
        "username = whoami()['name']\n",
        "hf_repo_id = f\"{username}/functiongemma-270m-it-{model_name}\"\n",
        "\n",
        "repo_url = trained_model.push_to_hub(hf_repo_id, create_repo=True, commit_message=\"Upload model\")\n",
        "tokenizer.push_to_hub(hf_repo_id)\n",
        "\n",
        "card_content = f\"\"\"\n",
        "---\n",
        "base_model: {gemma_model}\n",
        "tags:\n",
        "- function-calling\n",
        "- mobile-actions\n",
        "- gemma\n",
        "---\n",
        "A fine-tuned model based on `{gemma_model}`.\"\"\"\n",
        "card = ModelCard(card_content)\n",
        "\n",
        "card.push_to_hub(hf_repo_id)\n",
        "\n",
        "print(f\"Uploaded to {repo_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePMIkvtMT24J"
      },
      "source": [
        "## Conversion to .litertlm for on-device deployment\n",
        "\n",
        "The first step is to install the necessary libraries using the `pip` package installer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No47TBwEjroB"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install ai-edge-torch-nightly --force-reinstall\n",
        "!pip install ai-edge-litert-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DimeKTEw7rbE"
      },
      "source": [
        "### Build the .litertlm from the fine-tuned model\n",
        "\n",
        "After running the script below, you can find the converted model in located in `/content/litertlm/mobile-actions_q8_ekv1024.litertlm` in the colab environment. Copy it to a persistent storage like Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1Sl__hlUWNP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from ai_edge_torch.generative.examples.gemma3 import gemma3\n",
        "from ai_edge_torch.generative.utilities import converter\n",
        "from ai_edge_torch.generative.utilities.export_config import ExportConfig\n",
        "from ai_edge_torch.generative.layers import kv_cache\n",
        "\n",
        "# Metadata for FunctionGemma\n",
        "llm_metadata = r\"\"\"start_token: {\n",
        "    token_ids: {\n",
        "        ids: [ 2 ]\n",
        "    }\n",
        "}\n",
        "stop_tokens: {\n",
        "    token_str: \"<end_of_turn>\"\n",
        "}\n",
        "stop_tokens: {\n",
        "    token_str: \"<start_function_response>\"\n",
        "}\n",
        "llm_model_type: {\n",
        "    function_gemma: {}\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "checkpoint_dir = \"/content/mobile-actions-functiongemma\"\n",
        "\n",
        "litertlm_output_dir = '/content/litertlm'\n",
        "os.makedirs(litertlm_output_dir, exist_ok=True)\n",
        "\n",
        "# Create the LLM metadata file\n",
        "metadata_path = os.path.join(litertlm_output_dir, 'base_llm_metadata.textproto')\n",
        "with open(metadata_path, 'w') as f:\n",
        "  f.write(llm_metadata)\n",
        "\n",
        "# Import the weights and build the PyTorch model\n",
        "pytorch_model = gemma3.build_model_270m(checkpoint_dir)\n",
        "\n",
        "# Setup the export configurations and parameters for text generation models.\n",
        "export_config = ExportConfig()\n",
        "export_config.kvcache_layout = kv_cache.KV_LAYOUT_TRANSPOSED\n",
        "export_config.mask_as_input = True\n",
        "\n",
        "# Convert to LiteRT-LM Format\n",
        "converter.convert_to_litert(\n",
        "    pytorch_model,\n",
        "    output_path=litertlm_output_dir,\n",
        "    output_name_prefix=\"mobile-actions\",\n",
        "    prefill_seq_len=256,\n",
        "    kv_cache_max_len=1024,\n",
        "    quantize=\"dynamic_int8\",\n",
        "    export_config=export_config,\n",
        "    tokenizer_model_path=os.path.join(checkpoint_dir, 'tokenizer.model'),\n",
        "    base_llm_metadata_path=metadata_path,\n",
        "    output_format=\"litertlm\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtnMtgeLbDsJ"
      },
      "source": [
        "### Save the `.litertlm` on Google Drive\n",
        "\n",
        "To deploy the converted model on [Google AI Edge Gallery](https://play.google.com/store/apps/details?id=com.google.ai.edge.gallery), we can first store the model on Google Drive. On the Gallery app, import the model from Google Drive later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otpmb9ZkZPpv"
      },
      "outputs": [],
      "source": [
        "#@title Mounting Google Drive on the colab environment\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIa4FHNebNFb"
      },
      "outputs": [],
      "source": [
        "#@title Save the `.litertlm` on Google Drive\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/mobile-actions/\n",
        "!cp /content/litertlm/mobile-actions_q8_ekv1024.litertlm /content/drive/MyDrive/mobile-actions/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f8ff452"
      },
      "source": [
        "## Summary and next steps\n",
        "\n",
        "Congratulations! You have completed the first part of [Fine-tune FunctionGemma 270M for Mobile Actions](https://ai.google.dev/gemma/docs/mobile-actions).\n",
        "\n",
        "You have successfully finetuned the FunctionGemma 270M with the Mobile Actions dataset and converted it to `.litertlm` format."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[FunctionGemma]Finetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d80046d09fb41dc90c1e751e3585a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ffa28040b7342128766d519e2488f65",
              "IPY_MODEL_a87475fa9d4942adb5aca4d73f2407dd",
              "IPY_MODEL_826934538537420d9db7bc91c49e596c"
            ],
            "layout": "IPY_MODEL_1b5dcf6096474425a000d58eda5fb2f1"
          }
        },
        "5ffa28040b7342128766d519e2488f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07e8012f61ab412d92706598b6c8c506",
            "placeholder": "",
            "style": "IPY_MODEL_9234fe652097401abcf7af02a0415b0c",
            "value": "Map:100%"
          }
        },
        "a87475fa9d4942adb5aca4d73f2407dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b64f71d152f4f97bb47f155176be5cc",
            "max": 9654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e30d43de4a24b3485cc602321421197",
            "value": 9654
          }
        },
        "826934538537420d9db7bc91c49e596c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f7eb6e17ae643329cf48e02f3f5f1bb",
            "placeholder": "",
            "style": "IPY_MODEL_2811c865e2eb4bbaa8b3761e61234931",
            "value": "9654/9654[00:43&lt;00:00,285.10examples/s]"
          }
        },
        "1b5dcf6096474425a000d58eda5fb2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e8012f61ab412d92706598b6c8c506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9234fe652097401abcf7af02a0415b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b64f71d152f4f97bb47f155176be5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e30d43de4a24b3485cc602321421197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f7eb6e17ae643329cf48e02f3f5f1bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2811c865e2eb4bbaa8b3761e61234931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80eec03bac484a84b4c1a06098897179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9985d0bd4b4946b4a4f48143d8d252f1",
              "IPY_MODEL_2e5d8404df91478bb8f15860f49ed795",
              "IPY_MODEL_73c5b674d8b445d6ab4c23ac54e3d937"
            ],
            "layout": "IPY_MODEL_925bcfb33aeb42299df5083e813b2c7e"
          }
        },
        "9985d0bd4b4946b4a4f48143d8d252f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8d5cd1d90084c9c81e3cf8c56b9fc10",
            "placeholder": "",
            "style": "IPY_MODEL_6bb7b5b8c8b04334a7b07c93557b8816",
            "value": "Filter:100%"
          }
        },
        "2e5d8404df91478bb8f15860f49ed795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c619e61d12a4f7d92f39d63f7416ea1",
            "max": 9654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae84b60a431c4da6be22321fad4d69bf",
            "value": 9654
          }
        },
        "73c5b674d8b445d6ab4c23ac54e3d937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb3ab909f7b442b690cc1d9132b3ffe2",
            "placeholder": "",
            "style": "IPY_MODEL_4f50bdef63d64396888536910140104d",
            "value": "9654/9654[00:00&lt;00:00,23705.06examples/s]"
          }
        },
        "925bcfb33aeb42299df5083e813b2c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8d5cd1d90084c9c81e3cf8c56b9fc10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb7b5b8c8b04334a7b07c93557b8816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c619e61d12a4f7d92f39d63f7416ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae84b60a431c4da6be22321fad4d69bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb3ab909f7b442b690cc1d9132b3ffe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f50bdef63d64396888536910140104d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "855f09cd58d94ef48d68b16f6e896b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db41fc74b27e422f8a08729acdb06c55",
              "IPY_MODEL_cc43ef1d0fd94c4a83087c61595e3cc3",
              "IPY_MODEL_f8afc06b8726412fb29f7d27ddf8b0e3"
            ],
            "layout": "IPY_MODEL_44fa6fb5de504c3c8fd000d0dbbc3b24"
          }
        },
        "db41fc74b27e422f8a08729acdb06c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ce90dcbd2141258d8e013fee936f83",
            "placeholder": "",
            "style": "IPY_MODEL_1cbf277fd5ef43ebbe419478d6327f45",
            "value": "Filter:100%"
          }
        },
        "cc43ef1d0fd94c4a83087c61595e3cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d020672060e34e7c9dd41475570e72a4",
            "max": 9654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdee2521bd1d40bf98f839fc7099677c",
            "value": 9654
          }
        },
        "f8afc06b8726412fb29f7d27ddf8b0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea9a2d8441640ae90bfcae942baf6bb",
            "placeholder": "",
            "style": "IPY_MODEL_6475852034d34a548e812fd7e0c7b02e",
            "value": "9654/9654[00:00&lt;00:00,26771.36examples/s]"
          }
        },
        "44fa6fb5de504c3c8fd000d0dbbc3b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ce90dcbd2141258d8e013fee936f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cbf277fd5ef43ebbe419478d6327f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d020672060e34e7c9dd41475570e72a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdee2521bd1d40bf98f839fc7099677c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aea9a2d8441640ae90bfcae942baf6bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6475852034d34a548e812fd7e0c7b02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf392075ed3f401eaa55311f56029c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4492bb93d5c54593853517bd37ede31a",
              "IPY_MODEL_79c56fca027c4b44bb403beb1c1acb85",
              "IPY_MODEL_9150d9d5181c4dc6a32be69a287a62e3"
            ],
            "layout": "IPY_MODEL_48fe605f86ed419c83309b5e9a91b876"
          }
        },
        "4492bb93d5c54593853517bd37ede31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07ea87d5efc343e19523125abdcdc69b",
            "placeholder": "",
            "style": "IPY_MODEL_814b4e0491cf48ffb6d615623a527273",
            "value": "Tokenizingtraindataset:100%"
          }
        },
        "79c56fca027c4b44bb403beb1c1acb85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31268130e4834d2c8be58a1ca65d491c",
            "max": 8693,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d947fcd02fcc47c48761f093ce9fa53d",
            "value": 8693
          }
        },
        "9150d9d5181c4dc6a32be69a287a62e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c74b5826d814b19a9eb6db3950c701f",
            "placeholder": "",
            "style": "IPY_MODEL_59701d51df4f4cd5b9f6ead462a3831f",
            "value": "8693/8693[01:07&lt;00:00,53.21examples/s]"
          }
        },
        "48fe605f86ed419c83309b5e9a91b876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ea87d5efc343e19523125abdcdc69b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814b4e0491cf48ffb6d615623a527273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31268130e4834d2c8be58a1ca65d491c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d947fcd02fcc47c48761f093ce9fa53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c74b5826d814b19a9eb6db3950c701f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59701d51df4f4cd5b9f6ead462a3831f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3179477a077e42a19161c51b81f12361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6bc25edf34e462c839886f523645f21",
              "IPY_MODEL_9189ded7cbae48b58ce83cf44a9cd2a3",
              "IPY_MODEL_577ab9fb6e2449fb831f48b7995d04d0"
            ],
            "layout": "IPY_MODEL_2e18c3382d75486ab2051da348c9871f"
          }
        },
        "e6bc25edf34e462c839886f523645f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a631d9b202a04887a8b50854cefb0d06",
            "placeholder": "",
            "style": "IPY_MODEL_3066dcb3bc6b46fe805ed75051fbdc8f",
            "value": "Truncatingtraindataset:100%"
          }
        },
        "9189ded7cbae48b58ce83cf44a9cd2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10b6df3c79414365af117b57fee4ba42",
            "max": 8693,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53e82cab04da4a52ae0fce0d347b3ba4",
            "value": 8693
          }
        },
        "577ab9fb6e2449fb831f48b7995d04d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cde938b2cde473a92c76d1282becc22",
            "placeholder": "",
            "style": "IPY_MODEL_abe044d423ba4977aa59198c359b704d",
            "value": "8693/8693[00:00&lt;00:00,21192.02examples/s]"
          }
        },
        "2e18c3382d75486ab2051da348c9871f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a631d9b202a04887a8b50854cefb0d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3066dcb3bc6b46fe805ed75051fbdc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10b6df3c79414365af117b57fee4ba42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e82cab04da4a52ae0fce0d347b3ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cde938b2cde473a92c76d1282becc22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abe044d423ba4977aa59198c359b704d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "057e930576b54b93bc47c44617d111da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4c9229302444a3e921c9775f587ad74",
              "IPY_MODEL_b06421929c6348888247c159b34cbbed",
              "IPY_MODEL_dac6131e21094e69b976e38f0591e829"
            ],
            "layout": "IPY_MODEL_8e1648e6e66a4cd0aeda87fdce506be3"
          }
        },
        "e4c9229302444a3e921c9775f587ad74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70c821bf3444af987048e8c3ce0bf44",
            "placeholder": "",
            "style": "IPY_MODEL_fe0a6db6bb264c5e99df64b6f1930707",
            "value": "AddingEOStoevaldataset:100%"
          }
        },
        "b06421929c6348888247c159b34cbbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_961167ebdaac40f6aa212526d0ba41c8",
            "max": 961,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c26a04a1727547a9b86b9fca9378d9f3",
            "value": 961
          }
        },
        "dac6131e21094e69b976e38f0591e829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95278ec875754236882a6c376408a174",
            "placeholder": "",
            "style": "IPY_MODEL_6b86c9d97cf74b1eb9be717548a7d6fd",
            "value": "961/961[00:00&lt;00:00,2569.59examples/s]"
          }
        },
        "8e1648e6e66a4cd0aeda87fdce506be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b70c821bf3444af987048e8c3ce0bf44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0a6db6bb264c5e99df64b6f1930707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "961167ebdaac40f6aa212526d0ba41c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26a04a1727547a9b86b9fca9378d9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95278ec875754236882a6c376408a174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b86c9d97cf74b1eb9be717548a7d6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc0a70736eeb43d695ff6d402bc680a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5ca0b3070bc448086cc44788a612b3d",
              "IPY_MODEL_2becf97bf0014e20aba928f3786c1637",
              "IPY_MODEL_333480bf34c04a639a3773d8c72e1c27"
            ],
            "layout": "IPY_MODEL_0a41924ce0584068aca717e821c4d6f1"
          }
        },
        "a5ca0b3070bc448086cc44788a612b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffa45f545da7478f9e72736a55946a59",
            "placeholder": "",
            "style": "IPY_MODEL_2b796c73bd144ce9920d4e9236901236",
            "value": "Tokenizingevaldataset:100%"
          }
        },
        "2becf97bf0014e20aba928f3786c1637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0440d6b52dc48d2b2cbc6ee3dbdacf2",
            "max": 961,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39ff2efdea3244f597a00c7b2d7b6237",
            "value": 961
          }
        },
        "333480bf34c04a639a3773d8c72e1c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f16e9584ccc546bd900ae440ebd4fa31",
            "placeholder": "",
            "style": "IPY_MODEL_8ac5a38f5ee4463d93cc6c1d4dbf452c",
            "value": "961/961[00:07&lt;00:00,214.40examples/s]"
          }
        },
        "0a41924ce0584068aca717e821c4d6f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa45f545da7478f9e72736a55946a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b796c73bd144ce9920d4e9236901236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0440d6b52dc48d2b2cbc6ee3dbdacf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ff2efdea3244f597a00c7b2d7b6237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f16e9584ccc546bd900ae440ebd4fa31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ac5a38f5ee4463d93cc6c1d4dbf452c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d7a58e102b44c50bfe1c521619fa0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e16035f600b045f2834c4dbe83438f82",
              "IPY_MODEL_8de7b12c5e094a3e903d50bdb19ce67a",
              "IPY_MODEL_d8924ab3e108476e838a264a1bdba900"
            ],
            "layout": "IPY_MODEL_a5f29223d1564b17a460d48fe9f206b9"
          }
        },
        "e16035f600b045f2834c4dbe83438f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_021f97c3652e48bea6a76f92a0d14cca",
            "placeholder": "",
            "style": "IPY_MODEL_79af8d8dfae142ad8f0722fd0a791d32",
            "value": "Truncatingevaldataset:100%"
          }
        },
        "8de7b12c5e094a3e903d50bdb19ce67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85773d49a89495087e5dfc456f50379",
            "max": 961,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffacb061524e42718b5f21da5266407c",
            "value": 961
          }
        },
        "d8924ab3e108476e838a264a1bdba900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edc7339a5ad4cd2a263a6f711105172",
            "placeholder": "",
            "style": "IPY_MODEL_04ff538b5f6941988cb9bac0b5cb5b34",
            "value": "961/961[00:00&lt;00:00,19798.84examples/s]"
          }
        },
        "a5f29223d1564b17a460d48fe9f206b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "021f97c3652e48bea6a76f92a0d14cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79af8d8dfae142ad8f0722fd0a791d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d85773d49a89495087e5dfc456f50379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffacb061524e42718b5f21da5266407c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4edc7339a5ad4cd2a263a6f711105172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ff538b5f6941988cb9bac0b5cb5b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}